{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 13:41:26.424246: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-10 13:41:26.607117: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 444.1168 - mse: 444.1168\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 119.6664 - mse: 119.6664\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 89.0569 - mse: 89.0569\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 76.5909 - mse: 76.5909\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.7216 - mse: 81.7216\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.9513 - mse: 80.9513\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 91.0844 - mse: 91.0844\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.1884 - mse: 83.1884\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.5815 - mse: 80.5815\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 88.3844 - mse: 88.3844\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.8119 - mse: 75.8119\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.0914 - mse: 83.0914\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 87.5833 - mse: 87.5832\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 87.9075 - mse: 87.9075\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 78.2815 - mse: 78.2815\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.7876 - mse: 75.7876\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 96.0880 - mse: 96.0880\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.9727 - mse: 88.9727\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 88.2788 - mse: 88.2788\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 92.6226 - mse: 92.6226\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 92.3457 - mse: 92.3457\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.8756 - mse: 79.8756\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 97.4232 - mse: 97.4232\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.3979 - mse: 80.3979\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.3200 - mse: 80.3200\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.3457 - mse: 88.3457\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.4614 - mse: 80.4614\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 87.1705 - mse: 87.1705\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.9102 - mse: 83.9102\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.7489 - mse: 78.7489\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 89.8154 - mse: 89.8154\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 109.9322 - mse: 109.9322\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 78.8795 - mse: 78.8795\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 93.0729 - mse: 93.0729\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.4672 - mse: 86.4672\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.9313 - mse: 88.9313\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 78.8281 - mse: 78.8281\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 98.8806 - mse: 98.8806\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.0920 - mse: 79.0920\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.2232 - mse: 79.2232\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.7105 - mse: 79.7105\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 86.6982 - mse: 86.6982\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.3900 - mse: 80.3900\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 88.0150 - mse: 88.0150\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.7785 - mse: 83.7785\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.8416 - mse: 93.8416\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 87.2621 - mse: 87.2621\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 85.1519 - mse: 85.1519\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 95.1322 - mse: 95.1321\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 90.6815 - mse: 90.6815\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 83.5113 - mse: 83.5113\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.8764 - mse: 79.8764\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 89.7830 - mse: 89.7830\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 77.0290 - mse: 77.0290\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 81.9493 - mse: 81.9493\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 76.2215 - mse: 76.2215\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.5909 - mse: 84.5909\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 78.9538 - mse: 78.9538\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 90.1925 - mse: 90.1925\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 87.3311 - mse: 87.3311\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.8049 - mse: 81.8049\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 86.4526 - mse: 86.4526\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 92.0619 - mse: 92.0619\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 76.5608 - mse: 76.5608\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.3901 - mse: 82.3901\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.1435 - mse: 86.1435\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.9006 - mse: 84.9006\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 89.6308 - mse: 89.6308\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 75.0116 - mse: 75.0116\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.9172 - mse: 82.9172\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.9376 - mse: 93.9376\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 86.6093 - mse: 86.6093\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 82.2123 - mse: 82.2123\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.2459 - mse: 88.2459\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.9657 - mse: 82.9657\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.4197 - mse: 86.4197\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 93.9977 - mse: 93.9977\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 76.3306 - mse: 76.3306\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 79.6437 - mse: 79.6437\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 89.9584 - mse: 89.9584\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 91.9729 - mse: 91.9729\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.4745 - mse: 81.4745\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.2707 - mse: 83.2707\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 79.2023 - mse: 79.2023\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.0290 - mse: 84.0290\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 95.0783 - mse: 95.0783\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.1235 - mse: 80.1235\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.6855 - mse: 80.6855\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 87.0078 - mse: 87.0078\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 101.7859 - mse: 101.7859\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.6251 - mse: 82.6251\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 87.7952 - mse: 87.7952\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.4062 - mse: 82.4062\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.1033 - mse: 79.1033\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.0702 - mse: 93.0702\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 87.6217 - mse: 87.6217\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 83.5776 - mse: 83.5776\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 79.8797 - mse: 79.8797\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 97.3421 - mse: 97.3421\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 72.7287 - mse: 72.7287\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 80.9745 - mse: 80.9745\n",
      "loss:  80.97445678710938\n",
      "mse:  80.97445678710938\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "'''\n",
    "This is equivalent to the above code block\n",
    ">> model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(1))\n",
    "'''\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.027903 23.60372  23.60372  23.60372  23.60372  23.60372  23.60372\n",
      "  23.60372  23.60372  23.027903 23.027903 23.60372  23.60372  23.60372\n",
      "  23.027903 23.60372  23.60372  23.60372  23.027903 23.027903 23.027903\n",
      "  23.027903 23.60372  23.60372  23.60372  23.027903 23.60372  23.60372\n",
      "  23.027903 23.60372  23.60372  23.027903 23.60372  23.60372  23.027903\n",
      "  23.027903 23.60372  23.027903 23.027903 23.60372  23.60372  23.60372\n",
      "  23.027903 23.60372  23.60372  23.60372  23.60372  23.60372  23.027903\n",
      "  23.60372  23.60372  23.60372  23.027903 23.60372  23.60372  23.60372\n",
      "  23.027903 23.60372  23.60372  23.60372  23.027903 23.027903 23.027903\n",
      "  23.60372  23.60372  23.60372  23.027903 23.60372  23.027903 23.027903\n",
      "  23.027903 23.60372  23.027903 23.027903 23.60372  23.60372  23.60372\n",
      "  23.60372  23.60372  23.027903 23.60372  23.60372  23.60372  23.027903\n",
      "  23.60372  23.60372  23.027903 23.60372  23.60372  23.027903 23.60372\n",
      "  23.60372  23.60372  23.60372  23.60372  23.60372  23.60372  23.027903\n",
      "  23.60372  23.60372  23.60372  23.027903]]\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred.reshape(1,-1))\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 486.1087 - mse: 486.1087\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 177.3356 - mse: 177.3356\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 92.0664 - mse: 92.0664\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.0372 - mse: 80.0372\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 90.5611 - mse: 90.5611\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 82.2535 - mse: 82.2535\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 89.7757 - mse: 89.7757\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.2052 - mse: 88.2052\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 92.9484 - mse: 92.9484\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 87.0096 - mse: 87.0096\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.8388 - mse: 83.8388\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 88.5828 - mse: 88.5828\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 87.4038 - mse: 87.4038\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 84.0234 - mse: 84.0234\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 88.3956 - mse: 88.3956\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.3058 - mse: 80.3058\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6953 - mse: 84.6953\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 90.5296 - mse: 90.5296\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 91.8043 - mse: 91.8043\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 92.0540 - mse: 92.0540\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.3663 - mse: 72.3663\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 84.5330 - mse: 84.5330\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 78.8106 - mse: 78.8106\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.3255 - mse: 80.3255\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.9381 - mse: 86.9381\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 84.6176 - mse: 84.6176\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 76.3936 - mse: 76.3936\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.4112 - mse: 72.4112\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.4074 - mse: 72.4074\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 75.7617 - mse: 75.7617\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 74.2883 - mse: 74.2883\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.4315 - mse: 72.4315\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.2416 - mse: 65.2416\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 66.3257 - mse: 66.3257\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 82.6870 - mse: 82.6870\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.1805 - mse: 65.1805\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 69.6079 - mse: 69.6079\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 79.6749 - mse: 79.6749\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 67.6229 - mse: 67.6229\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 75.7849 - mse: 75.7849\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 75.1883 - mse: 75.1883\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 82.3051 - mse: 82.3051\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.8888 - mse: 76.8888\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 75.2268 - mse: 75.2268\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 66.7631 - mse: 66.7631\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.2655 - mse: 65.2655\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.4621 - mse: 69.4621\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 77.6592 - mse: 77.6592\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 58.9079 - mse: 58.9079\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 71.8508 - mse: 71.8508\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 71.3207 - mse: 71.3207\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 78.6779 - mse: 78.6779\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.8533 - mse: 63.8533\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.9099 - mse: 74.9099\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 79.6531 - mse: 79.6531\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 77.0222 - mse: 77.0222\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 71.1446 - mse: 71.1446\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 67.1440 - mse: 67.1440\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 60.6528 - mse: 60.6528\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70.8351 - mse: 70.8351\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.0626 - mse: 69.0626\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.2319 - mse: 70.2319\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.5329 - mse: 75.5329\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 64.4846 - mse: 64.4846\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.3605 - mse: 75.3605\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.3155 - mse: 69.3155\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.2866 - mse: 64.2866\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.4799 - mse: 68.4799\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 69.1099 - mse: 69.1099\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.9331 - mse: 72.9331\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.9857 - mse: 69.9857\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.5071 - mse: 69.5071\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.0594 - mse: 76.0594\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 64.4386 - mse: 64.4386\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.5495 - mse: 75.5495\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.2396 - mse: 80.2396\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.5745 - mse: 72.5745\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.6333 - mse: 70.6333\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.0928 - mse: 86.0928\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70.2452 - mse: 70.2452\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.0752 - mse: 72.0752\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 68.6839 - mse: 68.6839\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 71.0770 - mse: 71.0770\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.7123 - mse: 63.7123\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.2008 - mse: 70.2008\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 60.9185 - mse: 60.9185\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 78.1571 - mse: 78.1571\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.4126 - mse: 64.4126\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 64.9883 - mse: 64.9883\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 82.1169 - mse: 82.1169\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.9816 - mse: 64.9816\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 73.3205 - mse: 73.3205\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.4174 - mse: 68.4174\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.9858 - mse: 74.9858\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.8214 - mse: 79.8214\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.9620 - mse: 68.9620\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 66.3107 - mse: 66.3107\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 76.7530 - mse: 76.7530\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.7806 - mse: 69.7806\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.6437 - mse: 79.6437\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 63.4745 - mse: 63.4745\n",
      "loss:  63.474464416503906\n",
      "mse:  63.474464416503906\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(16, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(8))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(4))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "'''\n",
    "This is equivalent to the above code block\n",
    ">> model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(1))\n",
    "'''\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.038507 24.58256  24.58256  24.58256  24.58256  24.58256  24.58256\n",
      "  24.58256  24.58256  17.451231 13.038507 24.58256  24.58256  24.58256\n",
      "  17.451231 24.58256  24.58256  24.58256  17.451231 17.451231 17.451231\n",
      "  13.038507 24.58256  24.58256  24.58256  17.451231 24.58256  24.58256\n",
      "  13.038507 24.58256  24.58256  13.038507 24.58256  24.58256  17.451231\n",
      "  17.451231 24.58256  17.451231 17.451231 24.58256  24.58256  24.58256\n",
      "  17.451231 24.58256  24.58256  24.58256  24.58256  24.58256  17.451231\n",
      "  24.58256  24.58256  24.58256  17.451231 24.58256  24.58256  24.58256\n",
      "  17.451231 24.58256  24.58256  24.58256  17.451231 17.451231 17.451231\n",
      "  24.58256  24.58256  24.58256  17.451231 24.58256  17.451231 17.451231\n",
      "  17.451231 24.58256  17.451231 17.451231 24.58256  24.58256  24.58256\n",
      "  24.58256  24.58256  17.451231 24.58256  24.58256  24.58256  17.451231\n",
      "  24.58256  24.58256  17.451231 24.58256  24.58256  17.451231 24.58256\n",
      "  24.58256  24.58256  24.58256  24.58256  24.58256  24.58256  17.451231\n",
      "  24.58256  24.58256  24.58256  17.451231]]\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred.reshape(1,-1))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-course",
   "language": "python",
   "name": "quant-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
